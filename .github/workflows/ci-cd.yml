name: CI/CD Pipeline

on:
  push:
    branches: [main, master, develop]
  pull_request:
    branches: [main, master, develop]
  workflow_dispatch:  # Allow manual triggering

env:
  PYTHON_VERSION: "3.9"
  DOCKER_IMAGE_NAME: heart-disease-api
  DOCKER_IMAGE_TAG: latest

jobs:
  # Job 1: Code Quality and Linting
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Check code formatting with Black
        run: |
          black --check src/ tests/
        continue-on-error: false

      - name: Check import sorting with isort
        run: |
          isort --check-only src/ tests/
        continue-on-error: false

      - name: Run Flake8 linter
        run: |
          flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        continue-on-error: false

  # Job 2: Unit Testing
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run unit tests with coverage
        run: |
          pytest tests/ -v --cov=src --cov-report=xml --cov-report=html --cov-report=term-missing
        continue-on-error: false

      - name: Upload coverage reports
        uses: codecov/codecov@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: coverage-report
          path: htmlcov/
          retention-days: 30

  # Job 3: Data Download and Validation
  data-validation:
    name: Data Download and Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create data directory
        run: |
          mkdir -p data

      - name: Download dataset
        run: |
          python src/download_data.py
        continue-on-error: false

      - name: Validate dataset
        run: |
          python -c "
          import pandas as pd
          import sys
          df = pd.read_csv('data/heart.csv')
          print(f'Dataset shape: {df.shape}')
          print(f'Columns: {list(df.columns)}')
          print(f'Missing values: {df.isnull().sum().sum()}')
          if df.empty:
              print('ERROR: Dataset is empty!')
              sys.exit(1)
          print('Dataset validation passed!')
          "
        continue-on-error: false

  # Job 4: Model Training
  model-training:
    name: Model Training
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [code-quality, unit-tests, data-validation]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create necessary directories
        run: |
          mkdir -p data artifacts mlruns

      - name: Download dataset
        run: |
          python src/download_data.py

      - name: Train models
        run: |
          python src/train_model.py
        continue-on-error: false

      - name: Validate model artifacts
        run: |
          python -c "
          import os
          import sys
          from pathlib import Path
          
          # Check if MLflow runs exist
          mlruns_dir = Path('mlruns')
          if not mlruns_dir.exists() or not any(mlruns_dir.iterdir()):
              print('ERROR: MLflow runs directory is empty!')
              sys.exit(1)
          
          # Check if artifacts directory has files
          artifacts_dir = Path('artifacts')
          if not artifacts_dir.exists():
              print('ERROR: Artifacts directory does not exist!')
              sys.exit(1)
          
          print('Model artifacts validation passed!')
          "
        continue-on-error: false

      - name: Upload training artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: model-artifacts
          path: |
            artifacts/
            mlruns/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload training logs
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: training-logs
          path: |
            *.log
            logs/
          if-no-files-found: ignore
          retention-days: 7

  # Job 5: Docker Build and Test
  docker-build-test:
    name: Docker Build and Test
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [model-training]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Download model artifacts
        uses: actions/download-artifact@v3
        with:
          name: model-artifacts
          path: ./

      - name: Create necessary directories if missing
        run: |
          mkdir -p data artifacts mlruns

      - name: Download dataset for Docker build
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests
          python src/download_data.py || echo "Dataset download skipped"

      - name: Build Docker image
        run: |
          docker build -t ${{ env.DOCKER_IMAGE_NAME }}:${{ env.DOCKER_IMAGE_TAG }} -f docker/Dockerfile .
        continue-on-error: false

      - name: Test Docker image
        run: |
          # Start container in background
          docker run -d -p 8000:8000 --name test-api ${{ env.DOCKER_IMAGE_NAME }}:${{ env.DOCKER_IMAGE_TAG }}
          
          # Wait for API to be ready
          echo "Waiting for API to start..."
          sleep 15
          
          # Health check
          for i in {1..10}; do
            if curl -f http://localhost:8000/health; then
              echo "✓ API health check passed"
              break
            else
              echo "Attempt $i/10: API not ready yet..."
              sleep 3
            fi
          done
          
          # Test prediction endpoint
          echo "Testing prediction endpoint..."
          curl -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{
              "age": 63,
              "sex": 1,
              "cp": 3,
              "trestbps": 145,
              "chol": 233,
              "fbs": 1,
              "restecg": 0,
              "thalach": 150,
              "exang": 0,
              "oldpeak": 2.3,
              "slope": 0,
              "ca": 0,
              "thal": 1
            }' || echo "Prediction test failed"
          
          # Show container logs
          echo "Container logs:"
          docker logs test-api
        continue-on-error: false

      - name: Cleanup Docker containers
        if: always()
        run: |
          docker stop test-api || true
          docker rm test-api || true

      - name: Save Docker image
        if: success()
        run: |
          docker save ${{ env.DOCKER_IMAGE_NAME }}:${{ env.DOCKER_IMAGE_TAG }} | gzip > docker-image.tar.gz
        continue-on-error: false

      - name: Upload Docker image
        uses: actions/upload-artifact@v3
        if: success()
        with:
          name: docker-image
          path: docker-image.tar.gz
          retention-days: 7

  # Job 6: End-to-End Pipeline Test
  e2e-pipeline:
    name: End-to-End Pipeline Test
    runs-on: ubuntu-latest
    timeout-minutes: 40
    needs: [code-quality, unit-tests, data-validation]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Docker
        run: |
          sudo apt-get update
          sudo apt-get install -y docker.io
          sudo systemctl start docker
          sudo systemctl enable docker

      - name: Run end-to-end pipeline
        run: |
          chmod +x scripts/run_pipeline.sh
          ./scripts/run_pipeline.sh || exit 1
        continue-on-error: false

      - name: Upload pipeline logs
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: pipeline-logs
          path: |
            *.log
            logs/
          if-no-files-found: ignore
          retention-days: 7

  # Job 7: Summary and Notifications
  pipeline-summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, data-validation, model-training, docker-build-test]
    if: always()
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Generate pipeline summary
        run: |
          echo "## Pipeline Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Code Quality | ${{ needs.code-quality.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.unit-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Data Validation | ${{ needs.data-validation.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Model Training | ${{ needs.model-training.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Docker Build & Test | ${{ needs.docker-build-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.code-quality.result }}" == "success" ] && \
             [ "${{ needs.unit-tests.result }}" == "success" ] && \
             [ "${{ needs.data-validation.result }}" == "success" ] && \
             [ "${{ needs.model-training.result }}" == "success" ] && \
             [ "${{ needs.docker-build-test.result }}" == "success" ]; then
            echo "✅ **All pipeline stages passed successfully!**" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Pipeline failed. Please check the logs above.**" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

